{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/kranthi/anaconda3/lib/python3.7/site-packages/tqdm/std.py:656: FutureWarning: The Panel class is removed from pandas. Accessing it from the top-level namespace will also be removed in the next version\n",
      "  from pandas import Panel\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "import time\n",
    "import string\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from scipy.spatial.distance import cosine\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "\n",
    "from tqdm import tqdm, tqdm_notebook\n",
    "tqdm.pandas()\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter(\"ignore\")\n",
    "\n",
    "pd.options.display.max_colwidth = 200\n",
    "pd.options.display.max_rows = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = pd.read_csv(\"../data/train_ne.csv\")\n",
    "    test = pd.read_csv(\"../data/test_ne.csv\")\n",
    "    train.dropna(inplace=True)\n",
    "    print(\"Train Shape : {}\\nTest Shape :  {}\".format(train.shape, test.shape))\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (1199559, 5)\n",
      "Test Shape :  (92, 4)\n"
     ]
    }
   ],
   "source": [
    "train, test = get_data()\n",
    "target = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>fold_id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ziczac black red euro 44</td>\n",
       "      <td>clothing related products b2c shoes shoe laces</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>ziczac black red euro 44 clothing related products b2c shoes shoe laces</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9x9 resista 484938</td>\n",
       "      <td>publishing printing printing services</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>9x9 resista 484938 publishing printing printing services</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>halle pant short inseam 013049561d0010001 02</td>\n",
       "      <td>clothing related products b2c general</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>halle pant short inseam 013049561d0010001 02 clothing related products b2c general</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>harry houser travel expenses meals</td>\n",
       "      <td>security personnel</td>\n",
       "      <td>S</td>\n",
       "      <td>1</td>\n",
       "      <td>harry houser travel expenses meals security personnel</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tee time 740078609 greens fee composite</td>\n",
       "      <td>admissions green fees privately owned golf course</td>\n",
       "      <td>R</td>\n",
       "      <td>1</td>\n",
       "      <td>tee time 740078609 greens fee composite admissions green fees privately owned golf course</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                          title  \\\n",
       "0                      ziczac black red euro 44   \n",
       "1                            9x9 resista 484938   \n",
       "2  halle pant short inseam 013049561d0010001 02   \n",
       "3            harry houser travel expenses meals   \n",
       "4       tee time 740078609 greens fee composite   \n",
       "\n",
       "                                         description category  fold_id  \\\n",
       "0     clothing related products b2c shoes shoe laces        R        1   \n",
       "1              publishing printing printing services        S        1   \n",
       "2              clothing related products b2c general        R        1   \n",
       "3                                 security personnel        S        1   \n",
       "4  admissions green fees privately owned golf course        R        1   \n",
       "\n",
       "                                                                                        text  \n",
       "0                    ziczac black red euro 44 clothing related products b2c shoes shoe laces  \n",
       "1                                   9x9 resista 484938 publishing printing printing services  \n",
       "2         halle pant short inseam 013049561d0010001 02 clothing related products b2c general  \n",
       "3                                      harry houser travel expenses meals security personnel  \n",
       "4  tee time 740078609 greens fee composite admissions green fees privately owned golf course  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title           0\n",
       "description    16\n",
       "category        0\n",
       "text            0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test['description'][test['description'] == \"none\"] = np.nan\n",
    "test.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We have 16 descriptions null i.e ~18% (from Notebook 0)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imputing Descriptions\n",
    "\n",
    "We have seen from the above EDA that description holds a lot of weight in classifying products and services.\n",
    "\n",
    "So I here hypothsize what can be the ways we can impute the descriptions : \n",
    "\n",
    "1. Using Mean embedding of title to find nearest title in Train and then imputing the description of the mapped title in the train set.\n",
    "1. Using Doc2Vec to find similar documents \n",
    "1. Find a keyword in title to find the optimum description from train set ex : jean. Could be done by an custom-NER system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          1193949\n",
       "description       1279\n",
       "category             2\n",
       "fold_id             10\n",
       "text           1194957\n",
       "dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          89\n",
       "description    59\n",
       "category        2\n",
       "text           92\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.nunique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### As we have very less unique descriptions in train we hope to learn some-mapping as :  \n",
    "\n",
    "    [title --> description]\n",
    "    \n",
    "    \n",
    "I'm here using the cosine similarity between the sum of word vectors formed between train and test titles.\n",
    "\n",
    "The vectors here are the custom-trained Word2Vec model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def make_feature_vec(words, model, num_features):\n",
    "    \"\"\"\n",
    "    Average the word vectors for a set of words\n",
    "    \"\"\"\n",
    "    feature_vec = np.zeros((num_features,),dtype=\"float32\")  # pre-initialize (for speed)\n",
    "    nwords = 0.\n",
    "    index2word_set = set(model.wv.index2word)  # words known to the model\n",
    "\n",
    "    for word in words:\n",
    "        if word in index2word_set: \n",
    "            nwords = nwords + 1.\n",
    "            feature_vec = np.add(feature_vec, model[word])\n",
    "    \n",
    "    feature_vec = np.divide(feature_vec, nwords)\n",
    "    return feature_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1199559/1199559 [00:04<00:00, 246969.83it/s]\n",
      "100%|██████████| 92/92 [00:00<00:00, 100829.88it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(119951, 6)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['title_tokenized'] = train['title'].progress_apply(lambda x: x.split())\n",
    "test['title_tokenized'] = test['title'].progress_apply(lambda x: x.split())\n",
    "\n",
    "train_subsample = train[train['fold_id'] == 1]\n",
    "train_subsample.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Length of Vocabulary : 5814\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[('men', 0.9733667969703674),\n",
       " ('jacket', 0.9719110727310181),\n",
       " ('long', 0.970596969127655),\n",
       " ('button', 0.9678511023521423),\n",
       " ('ladies', 0.9666380882263184),\n",
       " ('polo', 0.9661392569541931),\n",
       " ('fleece', 0.9636504650115967),\n",
       " ('sleeve', 0.9608524441719055),\n",
       " ('women', 0.9590590596199036),\n",
       " ('boys', 0.9587820172309875)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col = 'title'\n",
    "values = train_subsample['{}_tokenized'.format(col)].values.tolist()\n",
    "model = Word2Vec(values, min_count=10)\n",
    "print(\"Length of Vocabulary : {}\".format(len(model.wv.vocab)))\n",
    "\n",
    "model.most_similar(\"shirt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c3c5f4b981d54f50bc00678c57528f67",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=119951.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "train_sentence_embs = np.zeros((train_subsample.shape[0], 100))\n",
    "\n",
    "for i in tqdm_notebook(range(train_subsample.shape[0])):\n",
    "    train_sentence_embs[i] = make_feature_vec(train['title_tokenized'].iloc[i], model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e83bed5b4de2455d8e93bf83bb511e68",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=92.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "test_sentence_embs = np.zeros((test.shape[0], 100))\n",
    "\n",
    "for i in tqdm_notebook(range(test.shape[0])):\n",
    "    test_sentence_embs[i] = make_feature_vec(test['title_tokenized'].iloc[i], model, 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_cosine_similarity(train_vecs, test_vec):\n",
    "    start_time = time.time()\n",
    "    result = np.full(len(train_vecs), -9999, dtype=float)\n",
    "    for idx, _ in enumerate(range(len(train_vecs))):\n",
    "        r = 1 - cosine(train_vecs[idx], test_vec)\n",
    "        if str(r) != \"nan\":\n",
    "            result[idx] = r\n",
    "    \n",
    "    print(\"Time Taken : {:.2f}\".format(time.time() - start_time))\n",
    "    \n",
    "    return np.argmax(result), result[np.argmax(result)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time Taken : 7.83\n",
      "Index : 41275 \t Similarity : 0.97726827899959\n",
      "Test Item : carpet repairs\n",
      "Train Title Item matched : repaired mechanical problem modified blocker bolt\n",
      "Train Description mapped : repair performed tpp equipment parts labor separately stated\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 8.39\n",
      "Index : 4608 \t Similarity : 0.9706081579707684\n",
      "Test Item : vct floor refinishing\n",
      "Train Title Item matched : fs436 us26d floor stop\n",
      "Train Description mapped : hardware sold medical facility\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 8.90\n",
      "Index : 43561 \t Similarity : 0.8863722690210839\n",
      "Test Item : clean carpet clean windows scrub buff vct floors\n",
      "Train Title Item matched : front porch actor windows ba\n",
      "Train Description mapped : computer software implementation prewritten software electronically downloaded\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 8.34\n",
      "Index : 28254 \t Similarity : 0.9849298534173451\n",
      "Test Item : apparel customization alterations\n",
      "Train Title Item matched : lv ur68 fu2z\n",
      "Train Description mapped : clothing related products b2c general\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 9.04\n",
      "Index : 24550 \t Similarity : 0.9802417295653095\n",
      "Test Item : auto scrub coat lvt wax tile floors\n",
      "Train Title Item matched : face mount auto belay bracket\n",
      "Train Description mapped : installation associated sale tpp equipment parts labor separately stated\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 8.27\n",
      "Index : 56328 \t Similarity : 0.9935246970241906\n",
      "Test Item : extension labor services\n",
      "Train Title Item matched : remote combustion tuning services labor\n",
      "Train Description mapped : professional services\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 7.52\n",
      "Index : 36164 \t Similarity : 0.9749678643157168\n",
      "Test Item : apparel uniform accessories\n",
      "Train Title Item matched : nwot ny ok beanie\n",
      "Train Description mapped : clothing related products b2c hats caps\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 9.89\n",
      "Index : 31700 \t Similarity : 0.963324460410861\n",
      "Test Item : window cleaning\n",
      "Train Title Item matched : 26967 fish window cleaning steve chastain\n",
      "Train Description mapped : asp hosted software server state\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 6284.25\n",
      "Index : 16057 \t Similarity : 0.9865019751596178\n",
      "Test Item : bathroom vestibule ssw santizing\n",
      "Train Title Item matched : diebold electric deal drawer 19319 deal drawer\n",
      "Train Description mapped : optional maintenance agreements related sale tangible personal property\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 8.03\n",
      "Index : 82624 \t Similarity : 0.9654759594241684\n",
      "Test Item : store cleaning\n",
      "Train Title Item matched : emergency response cleaning urine\n",
      "Train Description mapped : janitorial non residential\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 7.25\n",
      "Index : 38583 \t Similarity : 0.9812459400435223\n",
      "Test Item : carpet laminate wood floors\n",
      "Train Title Item matched : tim horton buffalo\n",
      "Train Description mapped : installation associated sale tpp labor\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 7.65\n",
      "Index : 51067 \t Similarity : 1.0\n",
      "Test Item : janitorial services\n",
      "Train Title Item matched : may2018 janitorial services tmc045\n",
      "Train Description mapped : janitorial non residential\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 7.39\n",
      "Index : 48693 \t Similarity : 0.9623934983941006\n",
      "Test Item : apparel patches\n",
      "Train Title Item matched : wrang ret greeley jn\n",
      "Train Description mapped : clothing related products b2c general\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 7.18\n",
      "Index : 3959 \t Similarity : 1.0\n",
      "Test Item : service\n",
      "Train Title Item matched : conveyor service\n",
      "Train Description mapped : installation associated sale tpp equipment parts labor separately stated\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 7.17\n",
      "Index : 73930 \t Similarity : 0.9569078794032791\n",
      "Test Item : repair maintenance services performed tpp include parts materials labor\n",
      "Train Title Item matched : completion repair services pricing parts applied separately replaced temple 2342 18\n",
      "Train Description mapped : repair performed tpp labor\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Time Taken : 7.14\n",
      "Index : 80613 \t Similarity : 0.9927926992956295\n",
      "Test Item : restorative carpet cleaning\n",
      "Train Title Item matched : carpet upholstery cleaning k4 1306 4477033780\n",
      "Train Description mapped : janitorial non residential\n",
      "----------------------------------------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "null_idxs = test[test['description'].isnull()].index.tolist()\n",
    "\n",
    "mapping = {}\n",
    "\n",
    "for i in null_idxs:\n",
    "    item = test['title'].iloc[i]\n",
    "    mapping[i] = {}\n",
    "    mapping[i]['test_title'] = item\n",
    "    \n",
    "    max_idx, max_sim = calc_cosine_similarity(train_sentence_embs, test_sentence_embs[i])\n",
    "    print(\"Index : {} \\t Similarity : {}\".format(max_idx, max_sim))\n",
    "\n",
    "    mapping[i]['train_title'] = train_subsample['title'].iloc[max_idx]\n",
    "    mapping[i]['mapped_desc'] = train_subsample['description'].iloc[max_idx]\n",
    "    \n",
    "    print(\"Test Item : {}\".format(item))\n",
    "    print(\"Train Title Item matched : {}\".format(mapping[i]['train_title']))\n",
    "    print(\"Train Description mapped : {}\".format(mapping[i]['mapped_desc']))\n",
    "    print(\"--\"*50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "for key, value in mapping.items():\n",
    "    test['description'].iloc[key] = value['mapped_desc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "test['text'] = test['title'] + \" \" + test['description']\n",
    "test.to_csv(\"../data/test_ne_imputed.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

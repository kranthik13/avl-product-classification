{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold, GroupShuffleSplit\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "import warnings\n",
    "warnings.simplefilter('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = pd.read_csv(\"../data/train.tsv\", sep=\"\\t\")\n",
    "    test = pd.read_csv(\"../data/test.csv\", sep=\"\\t\")\n",
    "    \n",
    "    print(\"Train Shape : {}\\nTest Shape :  {}\".format(train.shape, test.shape))\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (1200000, 3)\n",
      "Test Shape :  (92, 3)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ZicZac // Black + Red (Euro: 44)</td>\n",
       "      <td>Clothing &amp; related products (B2C) - Shoes and ...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>9X9 RESISTA/484938</td>\n",
       "      <td>Publishing/Printing - Printing Services</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Halle Pant - Short Inseam 013049561D0010001_ 02</td>\n",
       "      <td>Clothing &amp; related products (B2C) - General</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Harry Houser Travel Expenses - Meals</td>\n",
       "      <td>Security - personnel</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Tee Time: 740078609 : Greens Fee - Composite</td>\n",
       "      <td>Admissions - Green Fees for Privately Owned Go...</td>\n",
       "      <td>R</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             title  \\\n",
       "0                 ZicZac // Black + Red (Euro: 44)   \n",
       "1                               9X9 RESISTA/484938   \n",
       "2  Halle Pant - Short Inseam 013049561D0010001_ 02   \n",
       "3             Harry Houser Travel Expenses - Meals   \n",
       "4     Tee Time: 740078609 : Greens Fee - Composite   \n",
       "\n",
       "                                         description category  \n",
       "0  Clothing & related products (B2C) - Shoes and ...        R  \n",
       "1            Publishing/Printing - Printing Services        S  \n",
       "2        Clothing & related products (B2C) - General        R  \n",
       "3                               Security - personnel        S  \n",
       "4  Admissions - Green Fees for Privately Owned Go...        R  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train, test = get_data()\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dropping the 2 nulls in titles because as per the prrblem statement there is no possibility of null Title's."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.dropna(inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stratifying 10-Fold splitting train dataset as it is very large (1.2M)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split : 1\n",
      "------------------------------------------------------------\n",
      "Split : 2\n",
      "------------------------------------------------------------\n",
      "Split : 3\n",
      "------------------------------------------------------------\n",
      "Split : 4\n",
      "------------------------------------------------------------\n",
      "Split : 5\n",
      "------------------------------------------------------------\n",
      "Split : 6\n",
      "------------------------------------------------------------\n",
      "Split : 7\n",
      "------------------------------------------------------------\n",
      "Split : 8\n",
      "------------------------------------------------------------\n",
      "Split : 9\n",
      "------------------------------------------------------------\n",
      "Split : 10\n",
      "------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "skf = StratifiedKFold(n_splits=10, random_state=13)\n",
    "\n",
    "train['fold_id'] = np.nan\n",
    "\n",
    "for i, (trn_idx, val_idx) in enumerate(skf.split(train, train['category']), 1):\n",
    "    print(\"Split : {}\".format(i))\n",
    "    train['fold_id'].iloc[val_idx] = i\n",
    "    print(\"--\"*30)\n",
    "train['fold_id'] = train['fold_id'].astype(np.int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2     120001\n",
       "1     120001\n",
       "6     120000\n",
       "5     120000\n",
       "4     120000\n",
       "3     120000\n",
       "10    119999\n",
       "9     119999\n",
       "8     119999\n",
       "7     119999\n",
       "Name: fold_id, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['fold_id'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating the Validation Strategy + Splits\n",
    "\n",
    "As we have very less unique descriptions let's see there is a many-to-one relationship between Description and Target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train['description'].nunique() - train.groupby(['description'])['category'].value_counts().shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems we do have a fixed relationship between category and description and if we intend to include description (WE DO) we would have to make a group based validation strategy (group == description) so that we don't end up overfitting on descriptions and not genaralize."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GroupShuffleSplit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eca4dc8a041d40e89822ca40879e186a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train['source'] = np.nan\n",
    "\n",
    "new_df = pd.DataFrame()\n",
    "\n",
    "for i in tqdm_notebook(train['fold_id'].unique()):\n",
    "#     print(i)\n",
    "    gss = GroupShuffleSplit(n_splits=1, test_size=0.2, random_state=13)\n",
    "    train_subsample = train[train['fold_id'] == i].copy()\n",
    "    train_subsample.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    for idx, (trn_idx, val_idx) in enumerate(gss.split(\n",
    "        X=train_subsample, y=train_subsample['category'], groups=train_subsample['description'])):\n",
    "        \n",
    "        train_set = train_subsample.iloc[trn_idx]\n",
    "        valid_set = train_subsample.iloc[val_idx]\n",
    "\n",
    "        train_subsample['source'].iloc[trn_idx] = \"train\"\n",
    "        train_subsample['source'].iloc[val_idx] = \"valid\"\n",
    "        \n",
    "        print(len(set.intersection(set(train_set['description'].values), set(valid_set['description'].values))))\n",
    "    new_df = pd.concat([new_df, train_subsample], axis=0)\n",
    "    new_df.reset_index(drop=True, inplace=True)\n",
    "#     print(new_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "title          0\n",
       "description    0\n",
       "category       0\n",
       "fold_id        0\n",
       "source         0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = new_df.copy()\n",
    "del new_df\n",
    "gc.collect()\n",
    "\n",
    "train.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Subsampling the train to train multiple hypothesis faster."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>category</th>\n",
       "      <th>fold_id</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>03/22/18 Stationary Guard Service - Preciado, ...</td>\n",
       "      <td>Security - personnel</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2c92a09a6ff0d9eb0170001fa1386b8d</td>\n",
       "      <td>Data - processing - electronic output</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>WRLS_C35519-882-17</td>\n",
       "      <td>Internet Access</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2-4X4/DF AGENT NAME COVER UP AND POSTS REPAINT</td>\n",
       "      <td>Publishing/Printing - Printing Services</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>type=lppremium uid=85987272 dbid=11601222 dbid...</td>\n",
       "      <td>ASP - hosted software, server not in state</td>\n",
       "      <td>S</td>\n",
       "      <td>3</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               title  \\\n",
       "0  03/22/18 Stationary Guard Service - Preciado, ...   \n",
       "1                   2c92a09a6ff0d9eb0170001fa1386b8d   \n",
       "2                                 WRLS_C35519-882-17   \n",
       "3     2-4X4/DF AGENT NAME COVER UP AND POSTS REPAINT   \n",
       "4  type=lppremium uid=85987272 dbid=11601222 dbid...   \n",
       "\n",
       "                                  description category  fold_id source  \n",
       "0                        Security - personnel        S        3  train  \n",
       "1       Data - processing - electronic output        S        3  train  \n",
       "2                             Internet Access        S        3  train  \n",
       "3     Publishing/Printing - Printing Services        S        3  train  \n",
       "4  ASP - hosted software, server not in state        S        3  valid  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_subsample = train[train['fold_id'] == np.random.choice(train['fold_id'].unique())]\n",
    "train_subsample.reset_index(drop=True, inplace=True)\n",
    "train_subsample[['title', 'description', 'category', 'source']].to_csv(\"../data/v2/train_subsample.csv\", index=False)\n",
    "train_subsample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train.to_csv(\"../data/v2/train_10_skf.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "40"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "del train\n",
    "del test\n",
    "del train_subsample\n",
    "\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

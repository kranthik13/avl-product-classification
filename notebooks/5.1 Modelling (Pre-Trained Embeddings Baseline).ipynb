{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import gc\n",
    "import os \n",
    "import re \n",
    "import csv\n",
    "import time\n",
    "import codecs\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import logging\n",
    "from sklearn.metrics import roc_auc_score, f1_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D\n",
    "from keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten, Conv1D, BatchNormalization, GRU\n",
    "from keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n",
    "from keras.models import Model, load_model\n",
    "from keras import initializers, regularizers, constraints, optimizers, layers, callbacks\n",
    "from keras import backend as K\n",
    "from keras.engine import InputSpec, Layer\n",
    "from keras.callbacks import Callback, EarlyStopping, ModelCheckpoint, LearningRateScheduler\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "from tqdm import tqdm_notebook\n",
    "\n",
    "start_time = time.time()\n",
    "np.random.seed(32)\n",
    "os.environ[\"OMP_NUM_THREADS\"] = \"4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class F1Evaluation(Callback):\n",
    "    def __init__(self, validation_data=(), test_data=(), interval=1):\n",
    "        super(Callback, self).__init__()\n",
    "        \n",
    "        self.interval = interval\n",
    "        self.X_val, self.y_val = validation_data\n",
    "        self.X_test, self.y_test = test_data\n",
    "        self.y_val = self.y_val[:, 1]\n",
    "        self.y_test = self.y_test[:, 1]\n",
    "        self.T = 0.5\n",
    "    \n",
    "    def on_epoch_end(self, epoch, logs={}):\n",
    "        if epoch % self.interval == 0:\n",
    "            y_val = self.model.predict(self.X_val, verbose=0)[:, 1]\n",
    "            y_test = self.model.predict(self.X_test, verbose=0)[:, 1]\n",
    "            y_val[y_val >= self.T] = 1\n",
    "            y_val[y_val < self.T] = 0\n",
    "            y_test[y_test >= self.T] = 1\n",
    "            y_test[y_test < self.T] = 0\n",
    "            \n",
    "            val_score = f1_score(self.y_val, y_val)\n",
    "            test_score = f1_score(self.y_test, y_test)\n",
    "            print(\"F1 : Epoch : {} \\t Valid Score : {:.4f} \\t Test Score : {:.4f}\".format(epoch+1, val_score, test_score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data():\n",
    "    train = pd.read_csv(\"../input/avlpp-2/train_ne.csv\")\n",
    "    test = pd.read_csv(\"../input/avalaraproduct-classification/test_ne_imputed.csv\")\n",
    "    print(\"Train Shape : {}\\nTest Shape :  {}\".format(train.shape, test.shape))\n",
    "    \n",
    "    train = train[['fold_id', 'title', 'description', 'text', 'category', 'source']]\n",
    "    test = test[['title', 'description', 'text', 'category']]\n",
    "    train.dropna(inplace=True)\n",
    "    \n",
    "    return train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Shape : (1199998, 6)\n",
      "Test Shape :  (92, 5)\n"
     ]
    }
   ],
   "source": [
    "train, test = get_data()\n",
    "target = 'category'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fold_id</th>\n",
       "      <th>title</th>\n",
       "      <th>description</th>\n",
       "      <th>text</th>\n",
       "      <th>category</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>ziczac black red euro 44</td>\n",
       "      <td>clothing related products b2c shoes shoe laces</td>\n",
       "      <td>ziczac black red euro 44 clothing related prod...</td>\n",
       "      <td>R</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>9x9 resista 484938</td>\n",
       "      <td>publishing printing printing services</td>\n",
       "      <td>9x9 resista 484938 publishing printing printin...</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>halle pant short inseam 013049561d0010001 02</td>\n",
       "      <td>clothing related products b2c general</td>\n",
       "      <td>halle pant short inseam 013049561d0010001 02 c...</td>\n",
       "      <td>R</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>harry houser travel expenses meals</td>\n",
       "      <td>security personnel</td>\n",
       "      <td>harry houser travel expenses meals security pe...</td>\n",
       "      <td>S</td>\n",
       "      <td>train</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>tee time 740078609 greens fee composite</td>\n",
       "      <td>admissions green fees privately owned golf course</td>\n",
       "      <td>tee time 740078609 greens fee composite admiss...</td>\n",
       "      <td>R</td>\n",
       "      <td>valid</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fold_id                                         title  \\\n",
       "0        1                      ziczac black red euro 44   \n",
       "1        1                            9x9 resista 484938   \n",
       "2        1  halle pant short inseam 013049561d0010001 02   \n",
       "3        1            harry houser travel expenses meals   \n",
       "4        1       tee time 740078609 greens fee composite   \n",
       "\n",
       "                                         description  \\\n",
       "0     clothing related products b2c shoes shoe laces   \n",
       "1              publishing printing printing services   \n",
       "2              clothing related products b2c general   \n",
       "3                                 security personnel   \n",
       "4  admissions green fees privately owned golf course   \n",
       "\n",
       "                                                text category source  \n",
       "0  ziczac black red euro 44 clothing related prod...        R  valid  \n",
       "1  9x9 resista 484938 publishing printing printin...        S  train  \n",
       "2  halle pant short inseam 013049561d0010001 02 c...        R  train  \n",
       "3  harry houser travel expenses meals security pe...        S  train  \n",
       "4  tee time 740078609 greens fee composite admiss...        R  valid  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "K = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_classes = [\"target_R\", \"target_S\"]\n",
    "\n",
    "train[target] = train[target].map({\"R\": 0, \"S\": 1})\n",
    "train['target_S'] = np.nan\n",
    "train['target_R'] = np.nan\n",
    "train['target_R'] = 1 - train[target].values\n",
    "train['target_S'] = train[target].values\n",
    "\n",
    "train.drop([target], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "test[target] = test[target].map({\"R\": 0, \"S\": 1})\n",
    "test['target_S'] = np.nan\n",
    "test['target_R'] = np.nan\n",
    "test['target_R'] = 1 - test[target].values\n",
    "test['target_S'] = test[target].values\n",
    "\n",
    "test.drop([target], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Splitter\n",
    "\n",
    "def splitter(data, k=K):\n",
    "    \n",
    "    data_v1 = data[data['fold_id'] == k].copy()\n",
    "    data_v1.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    train_set = data_v1[data_v1['source'] == 'train'].copy()\n",
    "    valid_set = data_v1[data_v1['source'] == 'valid'].copy()\n",
    "    train_set.reset_index(drop=True, inplace=True)\n",
    "    valid_set.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    del data_v1\n",
    "    gc.collect()\n",
    "    \n",
    "#     print(train_set.shape, valid_set.shape)\n",
    "    \n",
    "    return train_set, valid_set, train_set[list_classes].values, valid_set[list_classes].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# visualize word length distribution\n",
    "train['doc_len'] = train['text'].apply(lambda words: len(words.split(\" \")))\n",
    "max_len = np.round(train['doc_len'].mean() + 2*train['doc_len'].std()).astype(int)\n",
    "\n",
    "sns.distplot(train['doc_len'], hist=True, kde=True, color='b', label='doc len')\n",
    "plt.axvline(x=max_len, color='k', linestyle='--', label='max len')\n",
    "plt.title('comment length')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "26"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "embed_size = 300\n",
    "embedding_path = \"../input/glove840b300dtxt/glove.840B.300d.txt\"\n",
    "max_features = 100000\n",
    "max_len = 50\n",
    "\n",
    "BS = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(99371, 8) (20593, 8) (99371, 2) (20593, 2)\n"
     ]
    }
   ],
   "source": [
    "y_test = test[list_classes].values\n",
    "\n",
    "X_train, X_valid, y_new_train, y_new_valid = splitter(train)\n",
    "print(X_train.shape, X_valid.shape, y_new_train.shape, y_new_valid.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_text_train = X_train['text'].str.lower()\n",
    "raw_text_valid = X_valid['text'].str.lower()\n",
    "raw_text_test = test['text'].str.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 6.81 s, sys: 54.4 ms, total: 6.87 s\n",
      "Wall time: 6.93 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tk = Tokenizer(num_words=max_features, lower=True)\n",
    "tk.fit_on_texts(raw_text_train.values.tolist() + raw_text_valid.values.tolist() + test['text'].values.tolist())\n",
    "X_train['seq'] = tk.texts_to_sequences(raw_text_train.values)\n",
    "X_valid['seq'] = tk.texts_to_sequences(raw_text_valid.values)\n",
    "test['seq'] = tk.texts_to_sequences(raw_text_test.values)\n",
    "\n",
    "X_train = pad_sequences(X_train.seq, maxlen=max_len)\n",
    "X_valid = pad_sequences(X_valid.seq, maxlen=max_len)\n",
    "test = pad_sequences(test.seq, maxlen=max_len)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Glove Baselining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4min 40s, sys: 7.03 s, total: 4min 47s\n",
      "Wall time: 4min 47s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "# GloVE\n",
    "def get_coefs(word, *arr):\n",
    "    return word, np.asarray(arr, dtype=\"float32\")\n",
    "embedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "59e784ad1a794aada9a97b4a4c43f4c3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=157153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of words : 100000\n",
      "Coverage : 28.82\n"
     ]
    }
   ],
   "source": [
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "cnt = 0\n",
    "for word, i in tqdm_notebook(word_index.items()):\n",
    "    if i>= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        cnt += 1\n",
    "\n",
    "cov = (cnt / nb_words)*100\n",
    "print(\"Number of words : {}\".format(nb_words))\n",
    "print(\"Coverage : {:.2f}\".format(cov))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modelling Utils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "N_EPOCHS = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model_cnn(test, embedding_matrix, lr=0.0, lr_d=0.0, units=0, dr=0.0, filename=\"cnn\"):\n",
    "    \n",
    "    file_path = \"cnn-{epoch:02d}.hdf5\"\n",
    "    check_point = ModelCheckpoint(file_path, monitor=\"val_loss\", verbose=1, save_best_only=False, save_weights_only=True, mode='auto', period=1)\n",
    "    f1_val = F1Evaluation(validation_data=(X_valid, y_new_valid), test_data=(test, y_test), interval=1)\n",
    "    early_stop = EarlyStopping(monitor=\"val_loss\", mode=\"min\", patience=5)\n",
    "\n",
    "    inp = Input(shape=(max_len, ))\n",
    "\n",
    "    x = Embedding(nb_words, embed_size, weights=[embedding_matrix], trainable=False)(inp)\n",
    "    x = Conv1D(128, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv1D(64, 3, activation='relu')(x)\n",
    "    x = MaxPooling1D(3)(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Conv1D(64, 3, activation='relu')(x)\n",
    "    x = Dropout(0.2)(x)\n",
    "    x = Flatten()(x)\n",
    "    x = Dense(2, activation='sigmoid')(x)\n",
    "    \n",
    "    model = Model(inputs=inp, outputs=x)\n",
    "    model.compile(loss=\"binary_crossentropy\", optimizer=Adam(lr=lr, decay=lr_d), metrics=['accuracy'])\n",
    "    history = model.fit(X_train, y_new_train, batch_size=BS, epochs=N_EPOCHS, validation_data=(X_valid, y_new_valid), verbose=1, \n",
    "                        callbacks=[f1_val, check_point, early_stop])\n",
    "    preds = model.predict(test, batch_size=1024, verbose=1)[:, 1]\n",
    "    \n",
    "    return model, preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99371 samples, validate on 20593 samples\n",
      "Epoch 1/5\n",
      "99371/99371 [==============================] - 6s 57us/step - loss: 0.1861 - accuracy: 0.9076 - val_loss: 0.3564 - val_accuracy: 0.8594\n",
      "F1 : Epoch : 1 \t Valid Score : 0.9020 \t Test Score : 0.8430\n",
      "\n",
      "Epoch 00001: saving model to cnn-01.hdf5\n",
      "Epoch 2/5\n",
      "99371/99371 [==============================] - 5s 49us/step - loss: 0.1409 - accuracy: 0.9259 - val_loss: 0.4974 - val_accuracy: 0.8166\n",
      "F1 : Epoch : 2 \t Valid Score : 0.8667 \t Test Score : 0.8430\n",
      "\n",
      "Epoch 00002: saving model to cnn-02.hdf5\n",
      "Epoch 3/5\n",
      "99371/99371 [==============================] - 5s 49us/step - loss: 0.1259 - accuracy: 0.9306 - val_loss: 0.4154 - val_accuracy: 0.8544\n",
      "F1 : Epoch : 3 \t Valid Score : 0.9015 \t Test Score : 0.8430\n",
      "\n",
      "Epoch 00003: saving model to cnn-03.hdf5\n",
      "Epoch 4/5\n",
      "99371/99371 [==============================] - 5s 47us/step - loss: 0.1161 - accuracy: 0.9341 - val_loss: 0.5109 - val_accuracy: 0.8269\n",
      "F1 : Epoch : 4 \t Valid Score : 0.8756 \t Test Score : 0.8361\n",
      "\n",
      "Epoch 00004: saving model to cnn-04.hdf5\n",
      "Epoch 5/5\n",
      "99371/99371 [==============================] - 5s 48us/step - loss: 0.1105 - accuracy: 0.9364 - val_loss: 0.5716 - val_accuracy: 0.7906\n",
      "F1 : Epoch : 5 \t Valid Score : 0.8492 \t Test Score : 0.8480\n",
      "\n",
      "Epoch 00005: saving model to cnn-05.hdf5\n",
      "92/92 [==============================] - 0s 33us/step\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "lr_d = 0\n",
    "units = 128\n",
    "dr = 0.2\n",
    "\n",
    "model, preds = build_model_cnn(test, embedding_matrix, lr, lr_d, units, dr, filename=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub = pd.DataFrame()\n",
    "sub['glove_pre'] = np.nan\n",
    "sub['fasttext_pre'] = np.nan\n",
    "sub['word2vec_pre'] = np.nan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "92/92 [==============================] - 0s 26us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glove_pre</th>\n",
       "      <th>fasttext_pre</th>\n",
       "      <th>word2vec_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.668374</td>\n",
       "      <td>0.513431</td>\n",
       "      <td>0.467357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.985637</td>\n",
       "      <td>0.864065</td>\n",
       "      <td>0.287055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.999998</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.605352</td>\n",
       "      <td>0.844581</td>\n",
       "      <td>0.091629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   glove_pre  fasttext_pre  word2vec_pre\n",
       "0   0.668374      0.513431      0.467357\n",
       "1   0.985637      0.864065      0.287055\n",
       "2   0.999998      0.999983      0.999927\n",
       "3   1.000000      0.999967      0.999992\n",
       "4   0.605352      0.844581      0.091629"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_id = 5\n",
    "model_path = \"cnn-0{}.hdf5\".format(epoch_id)\n",
    "model.load_weights(model_path)\n",
    "preds = model.predict(test, batch_size=1024, verbose=1)[:, 1]\n",
    "sub['glove_pre'] = preds\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GloVe : \n",
    "\n",
    "Coverage : 28.90 (What??? This might be due to the higher unique words which could be Company names and service names which are very domain-specific (services and prodcuts) domain).\n",
    "\n",
    "Best Test - F1 : 0.8689 (Well lesser than our BOW words models)\n",
    "\n",
    "PS : **baselined by CNN becuase it veryyyy fast**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: DeprecationWarning: Call to deprecated `wv` (Attribute will be removed in 4.0.0, use self instead).\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded 3000000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "# Word2Vec\n",
    "import gensim.models.keyedvectors as word2vec\n",
    "\n",
    "word2vecDict = word2vec.KeyedVectors.load_word2vec_format(\"../input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\", binary=True)\n",
    "embedding_index = dict()\n",
    "for word in word2vecDict.wv.vocab:\n",
    "    embedding_index[word] = word2vecDict.word_vec(word)\n",
    "print('Loaded {} word vectors.'.format(len(embedding_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d9ca4815d8d14517a3515c2bc98df43f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=157153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of words : 100000\n",
      "Coverage : 17.65\n"
     ]
    }
   ],
   "source": [
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "cnt = 0\n",
    "for word, i in tqdm_notebook(word_index.items()):\n",
    "    if i>= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        cnt += 1\n",
    "\n",
    "cov = (cnt / nb_words)*100\n",
    "print(\"Number of words : {}\".format(nb_words))\n",
    "print(\"Coverage : {:.2f}\".format(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99371 samples, validate on 20593 samples\n",
      "Epoch 1/5\n",
      "99371/99371 [==============================] - 5s 51us/step - loss: 0.2018 - accuracy: 0.8963 - val_loss: 0.4103 - val_accuracy: 0.7953\n",
      "F1 : Epoch : 1 \t Valid Score : 0.8497 \t Test Score : 0.8525\n",
      "\n",
      "Epoch 00001: saving model to cnn-01.hdf5\n",
      "Epoch 2/5\n",
      "99371/99371 [==============================] - 5s 48us/step - loss: 0.1543 - accuracy: 0.9171 - val_loss: 0.5569 - val_accuracy: 0.7812\n",
      "F1 : Epoch : 2 \t Valid Score : 0.8372 \t Test Score : 0.8595\n",
      "\n",
      "Epoch 00002: saving model to cnn-02.hdf5\n",
      "Epoch 3/5\n",
      "99371/99371 [==============================] - 5s 52us/step - loss: 0.1387 - accuracy: 0.9218 - val_loss: 0.5714 - val_accuracy: 0.7475\n",
      "F1 : Epoch : 3 \t Valid Score : 0.8076 \t Test Score : 0.8099\n",
      "\n",
      "Epoch 00003: saving model to cnn-03.hdf5\n",
      "Epoch 4/5\n",
      "99371/99371 [==============================] - 5s 51us/step - loss: 0.1290 - accuracy: 0.9261 - val_loss: 0.6144 - val_accuracy: 0.7902\n",
      "F1 : Epoch : 4 \t Valid Score : 0.8462 \t Test Score : 0.8595\n",
      "\n",
      "Epoch 00004: saving model to cnn-04.hdf5\n",
      "Epoch 5/5\n",
      "99371/99371 [==============================] - 5s 49us/step - loss: 0.1218 - accuracy: 0.9287 - val_loss: 0.6339 - val_accuracy: 0.7526\n",
      "F1 : Epoch : 5 \t Valid Score : 0.8141 \t Test Score : 0.8293\n",
      "\n",
      "Epoch 00005: saving model to cnn-05.hdf5\n",
      "92/92 [==============================] - 0s 41us/step\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "lr_d = 0\n",
    "units = 128\n",
    "dr = 0.2\n",
    "\n",
    "model, preds = build_model_cnn(test, embedding_matrix, lr, lr_d, units, dr, filename=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "92/92 [==============================] - 0s 33us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glove_pre</th>\n",
       "      <th>fasttext_pre</th>\n",
       "      <th>word2vec_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.467357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.287055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.091629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   glove_pre  fasttext_pre  word2vec_pre\n",
       "0        NaN           NaN      0.467357\n",
       "1        NaN           NaN      0.287055\n",
       "2        NaN           NaN      0.999927\n",
       "3        NaN           NaN      0.999992\n",
       "4        NaN           NaN      0.091629"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_id = 4\n",
    "model_path = \"cnn-0{}.hdf5\".format(epoch_id)\n",
    "model.load_weights(model_path)\n",
    "preds = model.predict(test, batch_size=1024, verbose=1)[:, 1]\n",
    "sub['word2vec_pre'] = preds\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec : \n",
    "\n",
    "Coverage : 17.65\n",
    "\n",
    "Best Test - F1 : **0.8595**\n",
    "\n",
    "PS : **baselined by CNN becuase it veryyyy fast**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FastText"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:4: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  after removing the cwd from sys.path.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5f431225c5d84adc8b847bcaf844b77e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=1.0, bar_style='info', max=1.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Loaded 111052 word vectors\n"
     ]
    }
   ],
   "source": [
    "# FastText\n",
    "embedding_index = {}\n",
    "f = codecs.open('../input/fasttext/wiki.simple.vec', encoding='utf-8')\n",
    "for line in tqdm_notebook(f):\n",
    "    values = line.rstrip().rsplit(' ')\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embedding_index[word] = coefs\n",
    "f.close()\n",
    "print('Loaded {} word vectors'.format(len(embedding_index)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.7/site-packages/ipykernel_launcher.py:6: TqdmDeprecationWarning: This function will be removed in tqdm==5.0.0\n",
      "Please use `tqdm.notebook.tqdm` instead of `tqdm.tqdm_notebook`\n",
      "  \n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7f45fabb065a4e82998450a1eea311ed",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(FloatProgress(value=0.0, max=157153.0), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Number of words : 100000\n",
      "Coverage : 17.18\n"
     ]
    }
   ],
   "source": [
    "word_index = tk.word_index\n",
    "nb_words = min(max_features, len(word_index))\n",
    "\n",
    "embedding_matrix = np.zeros((nb_words, embed_size))\n",
    "cnt = 0\n",
    "for word, i in tqdm_notebook(word_index.items()):\n",
    "    if i>= nb_words:\n",
    "        continue\n",
    "    embedding_vector = embedding_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector\n",
    "        cnt += 1\n",
    "\n",
    "cov = (cnt / nb_words)*100\n",
    "print(\"Number of words : {}\".format(nb_words))\n",
    "print(\"Coverage : {:.2f}\".format(cov))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 99371 samples, validate on 20593 samples\n",
      "Epoch 1/5\n",
      "99371/99371 [==============================] - 5s 53us/step - loss: 0.2068 - accuracy: 0.8927 - val_loss: 0.5973 - val_accuracy: 0.7326\n",
      "F1 : Epoch : 1 \t Valid Score : 0.7956 \t Test Score : 0.8067\n",
      "\n",
      "Epoch 00001: saving model to cnn-01.hdf5\n",
      "Epoch 2/5\n",
      "99371/99371 [==============================] - 5s 46us/step - loss: 0.1585 - accuracy: 0.9125 - val_loss: 0.5578 - val_accuracy: 0.7494\n",
      "F1 : Epoch : 2 \t Valid Score : 0.8089 \t Test Score : 0.8160\n",
      "\n",
      "Epoch 00002: saving model to cnn-02.hdf5\n",
      "Epoch 3/5\n",
      "99371/99371 [==============================] - 5s 49us/step - loss: 0.1425 - accuracy: 0.9185 - val_loss: 0.6832 - val_accuracy: 0.7399\n",
      "F1 : Epoch : 3 \t Valid Score : 0.8001 \t Test Score : 0.8130\n",
      "\n",
      "Epoch 00003: saving model to cnn-03.hdf5\n",
      "Epoch 4/5\n",
      "99371/99371 [==============================] - 5s 46us/step - loss: 0.1334 - accuracy: 0.9216 - val_loss: 0.5942 - val_accuracy: 0.8012\n",
      "F1 : Epoch : 4 \t Valid Score : 0.8548 \t Test Score : 0.7899\n",
      "\n",
      "Epoch 00004: saving model to cnn-04.hdf5\n",
      "Epoch 5/5\n",
      "99371/99371 [==============================] - 5s 49us/step - loss: 0.1256 - accuracy: 0.9249 - val_loss: 0.5285 - val_accuracy: 0.8771\n",
      "F1 : Epoch : 5 \t Valid Score : 0.9149 \t Test Score : 0.8065\n",
      "\n",
      "Epoch 00005: saving model to cnn-05.hdf5\n",
      "92/92 [==============================] - 0s 45us/step\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-3\n",
    "lr_d = 0\n",
    "units = 128\n",
    "dr = 0.2\n",
    "\n",
    "model, preds = build_model_cnn(test, embedding_matrix, lr, lr_d, units, dr, filename=\"cnn\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "92/92 [==============================] - 0s 25us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>glove_pre</th>\n",
       "      <th>fasttext_pre</th>\n",
       "      <th>word2vec_pre</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.513431</td>\n",
       "      <td>0.467357</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.864065</td>\n",
       "      <td>0.287055</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999983</td>\n",
       "      <td>0.999927</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.999967</td>\n",
       "      <td>0.999992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>0.844581</td>\n",
       "      <td>0.091629</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   glove_pre  fasttext_pre  word2vec_pre\n",
       "0        NaN      0.513431      0.467357\n",
       "1        NaN      0.864065      0.287055\n",
       "2        NaN      0.999983      0.999927\n",
       "3        NaN      0.999967      0.999992\n",
       "4        NaN      0.844581      0.091629"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "epoch_id = 2\n",
    "model_path = \"cnn-0{}.hdf5\".format(epoch_id)\n",
    "model.load_weights(model_path)\n",
    "preds = model.predict(test, batch_size=1024, verbose=1)[:, 1]\n",
    "sub['fasttext_pre'] = preds\n",
    "sub.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FastText : \n",
    "\n",
    "Coverage : 17.32\n",
    "\n",
    "Best F1 Test Score : **0.8160**\n",
    "\n",
    "PS : **baselined by CNN**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub.to_csv(\"pretrained_emb.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Compute-Heavy Approach to increase the coverage\n",
    "\n",
    "This might increase the coverage of the pre-trained embeddings most probably leading to an increase in F1 as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "ps = PorterStemmer()\n",
    "from nltk.stem.lancaster import LancasterStemmer\n",
    "lc = LancasterStemmer()\n",
    "from nltk.stem import SnowballStemmer\n",
    "sb = SnowballStemmer(\"english\")\n",
    "\n",
    "def load_glove(word_dict, lemma_dict):\n",
    "    EMBEDDING_FILE = '../input/embeddings/glove.840B.300d/glove.840B.300d.txt'\n",
    "    def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\n",
    "    embeddings_index = dict(get_coefs(*o.split(\" \")) for o in open(EMBEDDING_FILE))\n",
    "    embed_size = 300\n",
    "    nb_words = len(word_dict)+1\n",
    "    embedding_matrix = np.zeros((nb_words, embed_size), dtype=np.float32)\n",
    "    unknown_vector = np.zeros((embed_size,), dtype=np.float32) - 1.\n",
    "    print(unknown_vector[:5])\n",
    "    for key in tqdm(word_dict):\n",
    "        word = key\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.lower()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.upper()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = key.capitalize()\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = ps.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lc.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = sb.stem(key)\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        word = lemma_dict[key]\n",
    "        embedding_vector = embeddings_index.get(word)\n",
    "        if embedding_vector is not None:\n",
    "            embedding_matrix[word_dict[key]] = embedding_vector\n",
    "            continue\n",
    "        if len(key) > 1:\n",
    "            word = correction(key)\n",
    "            embedding_vector = embeddings_index.get(word)\n",
    "            if embedding_vector is not None:\n",
    "                embedding_matrix[word_dict[key]] = embedding_vector\n",
    "                continue\n",
    "        embedding_matrix[word_dict[key]] = unknown_vector                    \n",
    "    return embedding_matrix, nb_words "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion\n",
    "\n",
    "| Embedding  | Coverage  | F1  |\n",
    "|---|---|---|\n",
    "| Word2Vec  | 17.65  | 0.8595  |\n",
    "| FastText  | 17.32  | 0.8160  |\n",
    "| GloVe  | 28.82  | 0.8480  |\n",
    "\n",
    "---\n",
    "\n",
    "It seems that Word2Vec works best in these three pre-trained models but still lesser than our BOW Models.\n",
    "\n",
    "Reason : The reason for this might be because our task is to classify a product category based on its title and description and usually the products titles and description are not written in a semantic way rather its written in such a way which capture most of the important keywords representing the product. So the BOW models are better both in compute power as well as accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
